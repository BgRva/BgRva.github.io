<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[BgRva]]></title>
  <link href="http://bgrva.github.io/atom.xml" rel="self"/>
  <link href="http://bgrva.github.io/"/>
  <updated>2015-05-11T22:06:33-04:00</updated>
  <id>http://bgrva.github.io/</id>
  <author>
    <name><![CDATA[Michael Pastore]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[A New Graph Library for C#]]></title>
    <link href="http://bgrva.github.io/blog/2015/05/10/new-graph-library-for-csharp/"/>
    <updated>2015-05-10T10:01:01-04:00</updated>
    <id>http://bgrva.github.io/blog/2015/05/10/new-graph-library-for-csharp</id>
    <content type="html"><![CDATA[<p>You are probably thinking: <em>Really</em>?  Similar libraries exist and they are just fine, so why a new one?  Before I dive in to the pros and cons of this adventure, let me clarify what I mean by &ldquo;Graph&rdquo; Library. I&rsquo;m talking about a <a href="http://en.wikipedia.org/wiki/Graph_theory">graph</a> as set of nodes and edges where each edge connects two nodes.  There are several libraries available in C# that fall within this scope and they are all quite awesome. A few are listed below, but excluded are graph libraries for visualization or for specific purposes such as ontologies.</p>

<ul>
<li><a href="https://quickgraph.codeplex.com/">Quickgraph</a><br/></li>
<li><a href="https://github.com/SolutionsDesign/Algorithmia/">Algorithmia</a><br/></li>
</ul>


<p>The thing about implementing a graph in code is that it is all about compromises. Some implementations may emphasize speed, extensibility, customizability, etc., but each will have its strengths and weaknesses.  For example, here is a simple case of a compromise that may arise when considering a graph implementation as an <a href="http://en.wikipedia.org/wiki/Adjacency_list">adjacency list</a>. Assume we were implementing a graph and wanted to allow consumers of the code to access the nodes by index from 0 to n-1 (where n is the number of nodes in the graph) in O(1) time.  The code samples that follow are simply interface definitions for discussion purposes, implementation details are all hand-waving.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='csharp'><span class='line'><span class="k">public</span> <span class="k">interface</span> <span class="n">INode</span>
</span><span class='line'><span class="p">{</span>
</span><span class='line'>    <span class="kt">int</span> <span class="n">Index</span> <span class="p">{</span> <span class="k">get</span><span class="p">;</span> <span class="k">private</span> <span class="k">set</span><span class="p">;</span> <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="k">public</span> <span class="k">interface</span> <span class="n">IGraph</span>
</span><span class='line'><span class="p">{</span>
</span><span class='line'>    <span class="n">IList</span><span class="p">&lt;</span><span class="n">INode</span><span class="p">&gt;</span> <span class="n">Nodes</span> <span class="p">{</span> <span class="k">get</span><span class="p">;}</span>
</span><span class='line'>
</span><span class='line'>    <span class="kt">int</span> <span class="n">NodeCount</span> <span class="p">{</span> <span class="k">get</span><span class="p">;</span> <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// Given an instance of IGraph g, access nodes by index</span>
</span><span class='line'><span class="kt">var</span> <span class="n">node1</span> <span class="p">=</span> <span class="n">g</span><span class="p">.</span><span class="n">Nodes</span><span class="p">[</span><span class="m">1</span><span class="p">];</span>
</span><span class='line'><span class="kt">var</span> <span class="n">node2</span> <span class="p">=</span> <span class="n">g</span><span class="p">.</span><span class="n">Nodes</span><span class="p">[</span><span class="m">2</span><span class="p">];</span>
</span></code></pre></td></tr></table></div></figure>


<p>How nodes are accessed is coupled with how nodes are added and removed.  Should we allow the user to create a node object and add the node to the graph or should we allow the graph to handle creation of the node?  Each choice has implications for the rest of the implementation.  Consider the following two approaches for adding a node:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
</pre></td><td class='code'><pre><code class='csharp'><span class='line'><span class="k">public</span> <span class="k">interface</span> <span class="n">IGraph</span>
</span><span class='line'><span class="p">{</span>
</span><span class='line'>    <span class="n">List</span><span class="p">&lt;</span><span class="n">INode</span><span class="p">&gt;</span> <span class="n">Nodes</span> <span class="p">{</span> <span class="k">get</span><span class="p">;}</span>
</span><span class='line'>
</span><span class='line'>    <span class="kt">int</span> <span class="n">NodeCount</span> <span class="p">{</span> <span class="k">get</span><span class="p">;</span> <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1">/// &lt;summary&gt;</span>
</span><span class='line'>    <span class="c1">/// #1 The user creates the node and adds it to the graph object and returns</span>
</span><span class='line'>    <span class="c1">/// the graph assigned index of the node.</span>
</span><span class='line'>    <span class="c1">/// &lt;/summary&gt;</span>
</span><span class='line'>    <span class="kt">int</span> <span class="nf">AddNode</span><span class="p">(</span> <span class="n">INode</span> <span class="n">newNode</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1">/// &lt;summary&gt;</span>
</span><span class='line'>    <span class="c1">/// #2 The graph instance creates and returns the node object, with an assigned index</span>
</span><span class='line'>    <span class="c1">/// &lt;/summary&gt;</span>
</span><span class='line'>    <span class="n">INode</span> <span class="nf">AddNode</span><span class="p">()</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// Given an instance of IGraph g:</span>
</span><span class='line'><span class="c1">// #1</span>
</span><span class='line'><span class="kt">var</span> <span class="n">node1</span> <span class="p">=</span> <span class="k">new</span> <span class="n">Node</span><span class="p">();</span>
</span><span class='line'><span class="kt">var</span> <span class="n">index</span> <span class="p">=</span> <span class="n">g</span><span class="p">.</span><span class="n">AddNode</span><span class="p">(</span><span class="n">node1</span><span class="p">);</span>
</span><span class='line'><span class="kt">var</span> <span class="n">node</span> <span class="p">=</span> <span class="n">g</span><span class="p">.</span><span class="n">Nodes</span><span class="p">[</span><span class="n">index</span><span class="p">];</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// #2</span>
</span><span class='line'><span class="kt">var</span> <span class="n">g</span> <span class="p">=</span> <span class="k">new</span> <span class="n">Graph</span><span class="p">();</span>
</span><span class='line'><span class="kt">var</span> <span class="n">node</span> <span class="p">=</span> <span class="n">g</span><span class="p">.</span><span class="n">AddNode</span><span class="p">();</span>
</span></code></pre></td></tr></table></div></figure>


<p>Whereas #1 requires the user to instantiate a node, in #2 the graph maintains more control over instantiation but reduces the flexibility of where and how the user can create a node as the graph object must be instantiated first.  Both approaches still allow for accessing any node by index, but things get sticky when we consider removing a node:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='csharp'><span class='line'><span class="kt">var</span> <span class="n">g</span> <span class="p">=</span> <span class="k">new</span> <span class="n">Graph</span><span class="p">();</span>
</span><span class='line'><span class="c1">// create 10 nodes:</span>
</span><span class='line'><span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="p">=</span> <span class="m">0</span><span class="p">;</span> <span class="n">i</span><span class="p">&lt;</span> <span class="m">10</span><span class="p">;</span> <span class="n">i</span><span class="p">++)</span>
</span><span class='line'>    <span class="n">g</span><span class="p">.</span><span class="n">AddNode</span><span class="p">();</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// 10 nodes - nice; now iterate through them</span>
</span><span class='line'><span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="p">=</span> <span class="m">0</span><span class="p">;</span> <span class="n">i</span><span class="p">&lt;</span> <span class="n">g</span><span class="p">.</span><span class="n">NodeCount</span><span class="p">;</span> <span class="n">i</span><span class="p">++)</span>
</span><span class='line'>    <span class="n">Console</span><span class="p">.</span><span class="n">WriteLine</span><span class="p">(</span><span class="n">g</span><span class="p">.</span><span class="n">Nodes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">ToString</span><span class="p">());</span>
</span><span class='line'>
</span><span class='line'><span class="c1">//  *********: Here is the issue *********:</span>
</span><span class='line'><span class="n">g</span><span class="p">.</span><span class="n">RemoveNodeAt</span><span class="p">(</span><span class="m">4</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// 9 nodes; now iterate through them</span>
</span><span class='line'><span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="p">=</span> <span class="m">0</span><span class="p">;</span> <span class="n">i</span><span class="p">&lt;</span> <span class="n">g</span><span class="p">.</span><span class="n">NodeCount</span><span class="p">;</span> <span class="n">i</span><span class="p">++)</span>
</span><span class='line'>    <span class="n">Console</span><span class="p">.</span><span class="n">WriteLine</span><span class="p">(</span><span class="n">g</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">ToString</span><span class="p">())</span>
</span></code></pre></td></tr></table></div></figure>


<p>If the <em>IGraph</em> implementation provides the ability to access nodes by index from 0 to n-1 and we removed a node, the implementation needs to guarantee the indexing behavior.  This may require re-indexing all the nodes which is an O(n) operation.  If the graph is being implemented specifically for cases where users are just creating graphs from static data and do not require many removal operations, then this could be an acceptable solution.  Realistically, an O(n) operation is not that painful as iterating collections occurs very often.  But for large graphs with significant amounts of Add and Removal operatoins, this could impact user experience.  At the very least, such behavior and its implications should be clearly documented (in sample code as well) for the consumer.</p>

<p>So back to the call for a <strong>New Graph Library for C#</strong>. The driving idea (and need) for implementing this is to provide a general purpose graph structure that is quick to pick up, intuitive to use, and straight forward to represent data.  By &ldquo;general purpose&rdquo; we are not aiming to create a graph implementation optimized for narrow use cases (e.g. speed, memory, algorithms, etc.), but rather one that can be used in a wide latitude of cases needing a graph structure (and one which will handle particular issues such as Self-Loops and Parallel Edges).  Additionally, it needs to be small, uncluttered, and it needs to “just work”.  This implies quality documentation and sample code:  Not just more documentation, but the <em>right</em> documentation.  Finally, and perhaps most importantly, this will be built for <a href="http://www.dotnetfoundation.org/">.Net Core</a> so it can run on Mac, Linux, and Windows.</p>

<p>The name will inevitably come out of the initial discussions (though for some reason &ldquo;dream-graph&rdquo; with visions of flowers off of the <a href="http://scoobydoo.wikia.com/wiki/Mystery_Machine">Mystery Machine</a> have been jokingly put forth so far).  More to come and I invite you all to beat on it once the code starts flowing.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Snowball Extraction of a Sub-Network]]></title>
    <link href="http://bgrva.github.io/blog/2015/02/19/extract-subnet-by-steps/"/>
    <updated>2015-02-19T08:32:53-05:00</updated>
    <id>http://bgrva.github.io/blog/2015/02/19/extract-subnet-by-steps</id>
    <content type="html"><![CDATA[<p>What if you need a sub-network from a larger one, and how would you extract it?  I&rsquo;ll walk you through the steps of how to do a Snowball extraction, (or extraction by steps).  I have no doubt this goes by many names, but Snowball is the name I&rsquo;ve been familiar with for years.</p>

<p>Assume you are given a network, and by network I mean a graph structure with data attributes on the nodes and/or edges such that the graph represents data connected with respect to a particular context.  For example, take a simple graph:</p>

<p><img src="http://bgrva.github.io/images/simple-graph.jpg" width="326" height="254" title="'simple graph'" ></p>

<p>Add some names and now it is a simple social network:</p>

<p><img src="http://bgrva.github.io/images/simple-network.jpg" width="326" height="254" title="'simple social network'" ></p>

<p>Graph + Data = Network</p>

<h3>A Snowball Extration</h3>

<p>Lets start with the following example network and perform a snowball extraction 3 steps/hops out.</p>

<p><img src="http://bgrva.github.io/images/network-0.jpg" width="629" height="418"></p>

<p>Step 1: given a set of seed nodes: (2, 16), find all nodes 1 step or hop out from the seed nodes.  The nodes we are interested in are the neighbors of the seed nodes along <em>outgoing</em> edges, (in this example we will be considering the directionality of the edges).  Seed nodes are in green:</p>

<p><img src="http://bgrva.github.io/images/network-1.jpg" width="629" height="418"></p>

<p>Step 2: Now gather the new nodes found in Step 1: (1, 3, 9, 10, 36) and repeat the process:</p>

<p><img src="http://bgrva.github.io/images/network-2.jpg" width="629" height="418"></p>

<p>Step 3: Get the new nodes from step 2: (4, 6, 8, 1, 12, 17, 34) and repeat:</p>

<p><img src="http://bgrva.github.io/images/network-3.jpg" width="629" height="418"></p>

<p>Step 4: With the new nodes from step 3: (5, 7, 13, 15, 18, 19, 33), combine all found nodes and edges for the resulting sub-network:</p>

<p><img src="http://bgrva.github.io/images/network-4-final.jpg" width="629" height="418"></p>

<p>Note that using different seed nodes you may end up with a drastically different subnetwork and much depends on the structure and properties of the main network.  Additionally, how you handle duplicate edges, self-loops, and parallel-edges are completely determined by your problem at hand.  I&rsquo;ve attempted to formalize the steps as pseudo-code below, but again the complexities of the problem at hand will affect how this should be implemented.</p>

<figure class='code'><figcaption><span>pseudo-code</span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class='C#'><span class='line'><span class="n">foundNodes</span> <span class="p">{}</span>   <span class="c1">// all nodes found in the snowball so far</span>
</span><span class='line'><span class="n">currentNodes</span> <span class="p">{}</span> <span class="c1">// the current nodes from which we are stepping out</span>
</span><span class='line'><span class="n">currentEdges</span> <span class="p">{}</span> <span class="c1">// the edges we find outgoing from the current nodes</span>
</span><span class='line'><span class="n">maxStep</span> <span class="p">=</span> <span class="m">3</span>
</span><span class='line'><span class="n">currentStep</span> <span class="p">=</span> <span class="m">1</span>
</span><span class='line'>
</span><span class='line'><span class="n">nextNodes</span> <span class="p">=</span> <span class="p">{</span><span class="n">SEEDS</span><span class="p">}</span>  <span class="c1">// this should be initialized to the seeds 4,10</span>
</span><span class='line'>
</span><span class='line'><span class="k">while</span> <span class="p">(</span><span class="n">currentStep</span> <span class="p">&lt;=</span> <span class="n">maxStep</span><span class="p">)</span>
</span><span class='line'>  <span class="n">currentNodes</span> <span class="p">=</span> <span class="n">nextNodes</span><span class="p">;</span>
</span><span class='line'>  <span class="n">foundNodes</span><span class="p">.</span><span class="n">Add</span><span class="p">(</span><span class="n">currentNodes</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">foreach</span> <span class="n">each</span> <span class="n">edge</span>
</span><span class='line'>    <span class="n">If</span> <span class="n">edge</span><span class="p">.</span><span class="n">SourceId</span>  <span class="k">is</span> <span class="k">in</span> <span class="n">currentNodes</span>
</span><span class='line'>      <span class="n">currentEdges</span><span class="p">.</span><span class="n">Add</span><span class="p">(</span><span class="n">edge</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>  <span class="n">nextNodes</span> <span class="p">=</span> <span class="p">{}</span>
</span><span class='line'>  <span class="k">foreach</span> <span class="n">edge</span> <span class="k">in</span> <span class="n">currentEdges</span>
</span><span class='line'>    <span class="n">If</span> <span class="n">edge</span><span class="p">.</span><span class="n">TargetId</span> <span class="k">is</span> <span class="n">NOT</span> <span class="k">in</span> <span class="n">foundNodes</span>
</span><span class='line'>      <span class="n">nextNodes</span><span class="p">.</span><span class="n">Add</span><span class="p">(</span><span class="n">edge</span><span class="p">.</span><span class="n">TargetId</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How I Learned to Love YAML]]></title>
    <link href="http://bgrva.github.io/blog/2015/02/11/how-i-learned-to-love-yaml/"/>
    <updated>2015-02-11T10:01:01-05:00</updated>
    <id>http://bgrva.github.io/blog/2015/02/11/how-i-learned-to-love-yaml</id>
    <content type="html"><![CDATA[<p>This post describes how I came to use <a href="http://www.yaml.org/">YAML</a> to handle complex data scenarios for integration test cases.</p>

<p>As a proponent of TDD, generating test data is a necessity.  When the units under test increase in complexity, so does the test data.  Test data can range from simple input strings used in <a href="http://www.nunit.org/index.php?p=testCase&amp;r=2.5">NUnit TestCaseAttribue</a> entries to custom test scenario objects which included raw data as well as expectations of varying outcomes.</p>

<p>Generating complex test scenarios was especially the case when I was working on an application that did graph manipulation and required converting raw data to graph structures.  Because of the variations in graph structures that had to be handled when converting from input data, the test scenarios had to provide the raw data to be converted to a graph, the expected graph structure, and other expectations.  These custom scenario objects required creating code to read them in, to access the data and expectations, as well as managing changes  without requiring brain surgery on the codebase.</p>

<p>As an example of the range of test data needed for converting data to graphs,  here are 4 trivial examples of input data and the expected graph:</p>

<p><img src="http://bgrva.github.io/images/graph-variations.jpg" title="'graph examples'" ></p>

<p>The combinations of different sub-cases resulted in a multiple scenarios that needed to be built and managed. To compound things, each test case&rsquo;s data was hand jammed based on a known input an expected output.</p>

<p>In the past, I would end up with some fairly easy to read text file format and multiple parsers to ingest the files and create the scenario objects to feed the tests.  While the parsers themselves were simple and required limited error handling, the requirements of the scenarios would inevitably change over the course of the project.  For example, let’s say based on some new functionality, in order to implement the tests we needed to know the expected number of <em>self-loops</em> (an edge that has the same source and target node) for an input graph.  This would require adding a new property to the scenario object, updating the parsers, and verifying the parsers worked.  While not difficult or risky, these updates still sponge up valuable time and resources.</p>

<p>How come I didn’t format the data as XML or JSON?  Because the integration tests requiring the complex test data grew out of need rather than full up-front awareness and planning (these being developer level integration tests arising from TDD).  The data usually started out for use in simple unit tests, and over time it was aggregated to form a scenario.  The code to support the scenarios grew and morphed as the tests and the project code did.</p>

<p>Here is where <a href="http://www.yaml.org/">YAML</a> enters the picture.  Very briefly, YAML (<em>YAML Ain&rsquo;t Markup Language</em>) is a human friendly parse-able specification for which there exist parsers in multiple languages.  In other words, perfect for these test data scenarios.  There are many, many, awesome tutorials on it, so I will simply focus on how I used YAML to handle the scenario data.  For the examples below, I am using <a href="https://github.com/aaubry/YamlDotNet">YamlDotNet</a> by Antoine Aubry.  Though YAML.org identifies other .Net parsers, they have not been updated in quite some time. On top of that, YamlDotNet is very nice.</p>

<p>Here is the specification of a test scenario in YAML for example #4:</p>

<p><img src="http://bgrva.github.io/images/graph-variation-4.jpg" title="'graph example 4'" ></p>

<figure class='code'><figcaption><span>scenario 4 as yaml </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="nn">---</span>
</span><span class='line'>    <span class="l-Scalar-Plain">id</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">4</span>
</span><span class='line'>    <span class="l-Scalar-Plain">node-content-format</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">Name</span>
</span><span class='line'>    <span class="l-Scalar-Plain">edge-content-format</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">Empty</span>
</span><span class='line'>    <span class="l-Scalar-Plain">description</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">scenario to test parallel edges and self-loops including an orphan</span>
</span><span class='line'>    <span class="l-Scalar-Plain">raw-nodes</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">3</span>
</span><span class='line'>    <span class="l-Scalar-Plain">raw-edges</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">4</span>
</span><span class='line'>    <span class="l-Scalar-Plain">expected-nodes</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">3</span>
</span><span class='line'>    <span class="l-Scalar-Plain">expected-edges</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">4</span>
</span><span class='line'>    <span class="l-Scalar-Plain">expected-self-loops</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">2</span>
</span><span class='line'>
</span><span class='line'>    <span class="l-Scalar-Plain">nodes</span><span class="p-Indicator">:</span>
</span><span class='line'>        <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">id</span><span class="p-Indicator">:</span>    <span class="l-Scalar-Plain">0</span>
</span><span class='line'>          <span class="l-Scalar-Plain">content</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">(LEELA)</span>
</span><span class='line'>
</span><span class='line'>        <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">id</span><span class="p-Indicator">:</span>    <span class="l-Scalar-Plain">1</span>
</span><span class='line'>          <span class="l-Scalar-Plain">content</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">(FRY)</span>
</span><span class='line'>
</span><span class='line'>        <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">id</span><span class="p-Indicator">:</span>    <span class="l-Scalar-Plain">2</span>
</span><span class='line'>          <span class="l-Scalar-Plain">content</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">(BENDER)</span>
</span><span class='line'>
</span><span class='line'>    <span class="l-Scalar-Plain">edges</span><span class="p-Indicator">:</span>
</span><span class='line'>        <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">id</span><span class="p-Indicator">:</span>         <span class="l-Scalar-Plain">0</span>
</span><span class='line'>          <span class="l-Scalar-Plain">source-id</span><span class="p-Indicator">:</span>  <span class="l-Scalar-Plain">0</span>
</span><span class='line'>          <span class="l-Scalar-Plain">target-id</span><span class="p-Indicator">:</span>  <span class="l-Scalar-Plain">1</span>
</span><span class='line'>          <span class="l-Scalar-Plain">content</span><span class="p-Indicator">:</span>    <span class="l-Scalar-Plain">()</span>
</span><span class='line'>
</span><span class='line'>        <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">id</span><span class="p-Indicator">:</span>         <span class="l-Scalar-Plain">1</span>
</span><span class='line'>          <span class="l-Scalar-Plain">source-id</span><span class="p-Indicator">:</span>  <span class="l-Scalar-Plain">1</span>
</span><span class='line'>          <span class="l-Scalar-Plain">target-id</span><span class="p-Indicator">:</span>  <span class="l-Scalar-Plain">0</span>
</span><span class='line'>          <span class="l-Scalar-Plain">content</span><span class="p-Indicator">:</span>    <span class="l-Scalar-Plain">()</span>
</span><span class='line'>
</span><span class='line'>        <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">id</span><span class="p-Indicator">:</span>         <span class="l-Scalar-Plain">2</span>
</span><span class='line'>          <span class="l-Scalar-Plain">source-id</span><span class="p-Indicator">:</span>  <span class="l-Scalar-Plain">1</span>
</span><span class='line'>          <span class="l-Scalar-Plain">target-id</span><span class="p-Indicator">:</span>  <span class="l-Scalar-Plain">1</span>
</span><span class='line'>          <span class="l-Scalar-Plain">content</span><span class="p-Indicator">:</span>    <span class="l-Scalar-Plain">()</span>
</span><span class='line'>
</span><span class='line'>        <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">id</span><span class="p-Indicator">:</span>         <span class="l-Scalar-Plain">3</span>
</span><span class='line'>          <span class="l-Scalar-Plain">source-id</span><span class="p-Indicator">:</span>  <span class="l-Scalar-Plain">2</span>
</span><span class='line'>          <span class="l-Scalar-Plain">target-id</span><span class="p-Indicator">:</span>  <span class="l-Scalar-Plain">2</span>
</span><span class='line'>          <span class="l-Scalar-Plain">content</span><span class="p-Indicator">:</span>    <span class="l-Scalar-Plain">()</span>
</span><span class='line'>
</span><span class='line'>    <span class="l-Scalar-Plain">expected-structure</span><span class="p-Indicator">:</span> <span class="p-Indicator">[</span><span class="nv">0</span><span class="p-Indicator">,</span><span class="nv">1</span><span class="p-Indicator">,</span><span class="nv">0</span><span class="p-Indicator">]</span>
</span><span class='line'>                        <span class="p-Indicator">[</span><span class="nv">1</span><span class="p-Indicator">,</span><span class="nv">1</span><span class="p-Indicator">,</span><span class="nv">0</span><span class="p-Indicator">]</span>
</span><span class='line'>                        <span class="p-Indicator">[</span><span class="nv">0</span><span class="p-Indicator">,</span><span class="nv">0</span><span class="p-Indicator">,</span><span class="nv">1</span><span class="p-Indicator">]</span>
</span><span class='line'>
</span><span class='line'>    <span class="l-Scalar-Plain">expected-edge-structure</span><span class="p-Indicator">:</span> <span class="p-Indicator">[]</span>  <span class="p-Indicator">[</span><span class="nv">1</span><span class="p-Indicator">]</span> <span class="p-Indicator">[</span><span class="nv">0</span><span class="p-Indicator">]</span>
</span><span class='line'>                             <span class="p-Indicator">[</span><span class="nv">1</span><span class="p-Indicator">]</span> <span class="p-Indicator">[]</span>  <span class="p-Indicator">[]</span>
</span><span class='line'>                             <span class="p-Indicator">[</span><span class="nv">1</span><span class="p-Indicator">]</span> <span class="p-Indicator">[]</span>  <span class="p-Indicator">[]</span>
</span></code></pre></td></tr></table></div></figure>


<p>This test data was parsed in to a Scenario class instance that was used to feed integration tests:</p>

<figure class='code'><figcaption><span>Scenario class structure </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
</pre></td><td class='code'><pre><code class='C#'><span class='line'>  <span class="k">public</span> <span class="k">class</span> <span class="nc">Scenario</span>
</span><span class='line'>  <span class="p">{</span>
</span><span class='line'>    <span class="k">public</span> <span class="nf">Scenario</span><span class="p">()</span>
</span><span class='line'>    <span class="p">{</span>
</span><span class='line'>      <span class="n">Nodes</span> <span class="p">=</span> <span class="k">new</span> <span class="n">List</span><span class="p">&lt;</span><span class="n">NodeIndicator</span><span class="p">&gt;();</span>
</span><span class='line'>      <span class="n">Edges</span> <span class="p">=</span> <span class="k">new</span> <span class="n">List</span><span class="p">&lt;</span><span class="n">EdgeIndicator</span><span class="p">&gt;();</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">public</span> <span class="kt">int</span> <span class="n">Id</span> <span class="p">{</span> <span class="k">get</span><span class="p">;</span> <span class="k">set</span><span class="p">;</span> <span class="p">}</span>
</span><span class='line'>    <span class="k">public</span> <span class="kt">string</span> <span class="n">Description</span> <span class="p">{</span> <span class="k">get</span><span class="p">;</span> <span class="k">set</span><span class="p">;</span> <span class="p">}</span>
</span><span class='line'><span class="na">    [YamlAlias(&quot;node-content-format&quot;)]</span>
</span><span class='line'>    <span class="k">public</span> <span class="n">ScenarioNodeContentFormat</span> <span class="n">NodeContentFormat</span> <span class="p">{</span> <span class="k">get</span><span class="p">;</span> <span class="k">set</span><span class="p">;</span> <span class="p">}</span>
</span><span class='line'><span class="na">    [YamlAlias(&quot;edge-content-format&quot;)]</span>
</span><span class='line'>    <span class="k">public</span> <span class="n">ScenarioEdgeContentFormat</span> <span class="n">EdgeContentFormat</span> <span class="p">{</span> <span class="k">get</span><span class="p">;</span> <span class="k">set</span><span class="p">;</span> <span class="p">}</span>
</span><span class='line'>    <span class="k">public</span> <span class="n">List</span><span class="p">&lt;</span><span class="n">NodeIndicator</span><span class="p">&gt;</span> <span class="n">Nodes</span> <span class="p">{</span> <span class="k">get</span><span class="p">;</span> <span class="k">set</span><span class="p">;</span> <span class="p">}</span>
</span><span class='line'>    <span class="k">public</span> <span class="n">List</span><span class="p">&lt;</span><span class="n">EdgeIndicator</span><span class="p">&gt;</span> <span class="n">Edges</span> <span class="p">{</span> <span class="k">get</span><span class="p">;</span> <span class="k">set</span><span class="p">;</span> <span class="p">}</span>
</span><span class='line'><span class="na">    [YamlAlias(&quot;raw-nodes&quot;)]</span>
</span><span class='line'>    <span class="k">public</span> <span class="kt">int</span> <span class="n">NodeCountRaw</span> <span class="p">{</span> <span class="k">get</span><span class="p">;</span> <span class="k">set</span><span class="p">;</span> <span class="p">}</span>
</span><span class='line'><span class="na">    [YamlAlias(&quot;raw-edges&quot;)]</span>
</span><span class='line'>    <span class="k">public</span> <span class="kt">int</span> <span class="n">EdgeCountRaw</span> <span class="p">{</span> <span class="k">get</span><span class="p">;</span> <span class="k">set</span><span class="p">;</span> <span class="p">}</span>
</span><span class='line'><span class="na">    [YamlAlias(&quot;expected-nodes&quot;)]</span>
</span><span class='line'>    <span class="k">public</span> <span class="kt">int</span> <span class="n">NodeCountExpected</span> <span class="p">{</span> <span class="k">get</span><span class="p">;</span> <span class="k">set</span><span class="p">;</span> <span class="p">}</span>
</span><span class='line'><span class="na">    [YamlAlias(&quot;expected-edges&quot;)]</span>
</span><span class='line'>    <span class="k">public</span> <span class="kt">int</span> <span class="n">EdgeCountExpected</span> <span class="p">{</span> <span class="k">get</span><span class="p">;</span> <span class="k">set</span><span class="p">;</span> <span class="p">}</span>
</span><span class='line'><span class="na">    [YamlAlias(&quot;expected-self-loops&quot;)]</span>
</span><span class='line'>    <span class="k">public</span> <span class="kt">int</span> <span class="n">ExpectedSelfLoops</span> <span class="p">{</span> <span class="k">get</span><span class="p">;</span> <span class="k">set</span><span class="p">;</span> <span class="p">}</span>
</span><span class='line'><span class="na">    [YamlAlias(&quot;expected-structure&quot;)]</span>
</span><span class='line'>    <span class="k">public</span> <span class="kt">string</span> <span class="n">ExpectedStructure</span> <span class="p">{</span> <span class="k">get</span><span class="p">;</span> <span class="k">set</span><span class="p">;</span> <span class="p">}</span>
</span><span class='line'><span class="na">    [YamlAlias(&quot;expected-edge-structure&quot;)]</span>
</span><span class='line'>    <span class="k">public</span> <span class="kt">string</span> <span class="n">ExpectedEdgeStructure</span> <span class="p">{</span> <span class="k">get</span><span class="p">;</span> <span class="k">set</span><span class="p">;</span> <span class="p">}</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1">//---------- </span>
</span><span class='line'>  <span class="k">public</span> <span class="k">class</span> <span class="nc">EdgeIndicator</span>
</span><span class='line'>  <span class="p">{</span>
</span><span class='line'><span class="na">    [YamlAlias(&quot;source-id&quot;)]</span>
</span><span class='line'>    <span class="k">public</span> <span class="kt">int</span> <span class="n">SourceId</span> <span class="p">{</span> <span class="k">get</span><span class="p">;</span> <span class="k">set</span><span class="p">;</span> <span class="p">}</span>
</span><span class='line'><span class="na">    [YamlAlias(&quot;target-id&quot;)]</span>
</span><span class='line'>    <span class="k">public</span> <span class="kt">int</span> <span class="n">TargetId</span> <span class="p">{</span> <span class="k">get</span><span class="p">;</span> <span class="k">set</span><span class="p">;</span> <span class="p">}</span>
</span><span class='line'>    <span class="k">public</span> <span class="kt">string</span> <span class="n">Content</span> <span class="p">{</span> <span class="k">get</span><span class="p">;</span> <span class="k">set</span><span class="p">;</span> <span class="p">}</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1">//---------- </span>
</span><span class='line'>  <span class="k">public</span> <span class="k">class</span> <span class="nc">NodeIndicator</span>
</span><span class='line'>  <span class="p">{</span>
</span><span class='line'>    <span class="k">public</span> <span class="nf">NodeIndicator</span><span class="p">()</span>
</span><span class='line'>    <span class="p">{</span>
</span><span class='line'>      <span class="n">Id</span> <span class="p">=</span> <span class="p">-</span><span class="m">1</span><span class="p">;</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>    <span class="k">public</span> <span class="kt">int</span> <span class="n">Id</span> <span class="p">{</span> <span class="k">get</span><span class="p">;</span> <span class="k">set</span><span class="p">;</span> <span class="p">}</span>
</span><span class='line'>    <span class="k">public</span> <span class="kt">string</span> <span class="n">Content</span> <span class="p">{</span> <span class="k">get</span><span class="p">;</span> <span class="k">set</span><span class="p">;</span> <span class="p">}</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1">//---------- </span>
</span><span class='line'>  <span class="k">public</span> <span class="k">enum</span> <span class="n">ScenarioNodeContentFormat</span>
</span><span class='line'>  <span class="p">{</span>
</span><span class='line'>    <span class="n">Empty</span><span class="p">,</span>
</span><span class='line'>    <span class="n">Name</span><span class="p">,</span>
</span><span class='line'>  <span class="p">};</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1">//---------- </span>
</span><span class='line'>  <span class="k">public</span> <span class="k">enum</span> <span class="n">ScenarioEdgeContentFormat</span>
</span><span class='line'>  <span class="p">{</span>
</span><span class='line'>    <span class="n">Empty</span><span class="p">,</span>
</span><span class='line'>    <span class="n">Name</span><span class="p">,</span>
</span><span class='line'>  <span class="p">};</span>
</span><span class='line'>
</span><span class='line'>
</span></code></pre></td></tr></table></div></figure>


<p>Some explanations about the Scenario class:</p>

<ul>
<li><em>NodeIndicator</em> and <em>EdgeIndicator</em> are objects that &lsquo;indicate&rsquo; how a node or edge are to be constructed or connected, not the nodes or edges themselves.  It is up to the calling code that builds the graph to interpret this.</li>
<li>The <em>Content</em> property for each indicator represents a string into which different data can be associated with a node or edge.  For example, each node has a content value of a name surrounded by parenthesis:</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'>        <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">id</span><span class="p-Indicator">:</span>    <span class="l-Scalar-Plain">0</span>
</span><span class='line'>          <span class="l-Scalar-Plain">content</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">(LEELA)</span>
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>The format of the node and edge Content field is specified by the <em>NodeContentFormat</em> and <em>EdgeContentFormat</em> properties (respectively)</li>
<li>The <em>ExpectedStructure</em> is a string representation of the expected structure of the graph once it is constructed.  The string is a row-major representation of the graph as a matrix.</li>
<li>The <em>ExpectedEdgeStructure</em>  is a string representation of the expected connectivity of the edges in the resulting graph.  The format is as follows

<ul>
<li>Each row represents the edges indicent to a node starting at node index 0</li>
<li>The contents of each row are

<ul>
<li>First &lsquo;[]&rsquo; is an array of edge ids for self loops (* self loops are not included in the inbound or outbound arrays ).</li>
<li>Second &lsquo;[]&rsquo; is an array of edge ids for inbound edges</li>
<li>Third &lsquo;[]&rsquo; is an array of edge ids for outbound edges</li>
</ul>
</li>
</ul>
</li>
</ul>


<p>Now, if I need to add new data fields to support new tests, then only tricky thing is getting the YAML syntax correct in the data files and of course adding any new properties to the Scenario class. The parsing is handled by YamlDotNet no brain surgery is required.  If only I&rsquo;d found YAML earlier.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Deploy Crawler to EC2 With Scrapyd]]></title>
    <link href="http://bgrva.github.io/blog/2014/04/13/deploy-crawler-to-ec2-with-scrapyd/"/>
    <updated>2014-04-13T21:21:01-04:00</updated>
    <id>http://bgrva.github.io/blog/2014/04/13/deploy-crawler-to-ec2-with-scrapyd</id>
    <content type="html"><![CDATA[<p>This post will walk through using <a href="http://scrapyd.readthedocs.org/en/latest/">scrapyd</a> to deploy and manage a <a href="http://scrapy.org/">scrapy</a> spider from a local linux instance to a remote EC2 linux instance. The steps below were run on a local Ubuntu 12.04 instance any one of the free AWS linux Ubuntu 12.04 tiers. This is another step in the development of the scraping project described in the first post for which the indented goal is to have multiple instances of scrapy spiders crawling for extended periods of time and saving the items to a common database for further processing.</p>

<p>This post assumes you have scrapy and scrapyd installed on a local (linux) system, a working scrapy crawler, an AWS account, and have some knowledge of basic web security practices. Note: If you have not yet installed scrapy on your local system, when installing pip for scrapy, install the ‘setup tools’ and not the ‘distro tools’, as the setup tools will be needed by scrapyd for ‘egg-i-fying’ crawlers for deployment.</p>

<p>If you don’t have an AWS then get one set up first and spend some time reading about <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/IAMBestPractices.html">IAM best practices</a>. In particular, don’t use your main account credentials for development. Create a <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/IAMBestPractices.html#create-iam-users">new user</a> in your AWS account and assign that user admin rights and do all development with that user. This separates you development credentials from your master account credentials (which have your credit card).</p>

<h3>Setting up scrapy on a EC2 Ubuntu instance</h3>

<p>These are the broad steps I took to get an Ubuntu Server 12.04 LTS (free tier) instance up and running with scrapy and scrapyd installed. They do not cover all the details. If this is your first time with AWS, there are plenty of docs and quality videos available – invest some time in them.</p>

<p>1) Log into your AWS account</p>

<p>2) Go to your EC2 Dashboard</p>

<p>3) Create a Security Group with the following inbound and outbound rules:</p>

<p>Inbound (for inbound ssh and scrapyd communication):
<img src="http://bgrva.github.io/images/ec2-inbound-rules.jpg" title="inbound rules" alt="image of ec2 inbound rules"></p>

<p>Outbound (for outbound scrapyd and crawler http gets):
<img src="http://bgrva.github.io/images/ec2-outbound-rules.jpg" title="outbound rules" alt="image of ec2 outbound rules"></p>

<p>4) Create a key value pair for the ‘dev’ user and download it so you have access to it on your local system</p>

<p>5) Launch a linux instance and associate the security group and key value pair with this instance, (we will use my-ec2.amazonaws.com as the public dns of the instance)</p>

<p>6) When the instance is running, connect to the EC2 instance using the key-value pair, <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AccessingInstancesLinux.html">connect to your instance</a></p>

<p>8) Install scrapy and scrapyd on the EC2 instance</p>

<h3>Prepare the crawler for deployment</h3>

<p>Scrapyd deployment <a href="http://scrapyd.readthedocs.org/en/latest/deploy.html#show-and-define-targets">targets</a> are specified in a crawler’s <em>scrapy.cfg</em> file. The scrapyd commands to deploy a crawler need to be run in the root directory of your crawler project (or use fully qualified paths).</p>

<p>1) On your local system, go to the root folder of your crawler project</p>

<p>2) Edit <em>scrapy.cfg</em> by replacing any <em>deploy</em> sections so that the file looks like the following:</p>

<figure class='code'><figcaption><span>scrapy.cfg  </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c"># Automatically created by: scrapy startproject</span>
</span><span class='line'><span class="c">#</span>
</span><span class='line'><span class="c"># For more information about the [deploy] section see:</span>
</span><span class='line'><span class="c"># http://doc.scrapy.org/en/latest/topics/scrapyd.html</span>
</span><span class='line'>
</span><span class='line'><span class="p">[</span><span class="n">settings</span><span class="p">]</span>
</span><span class='line'><span class="n">default</span> <span class="o">=</span> <span class="n">projectX</span><span class="o">.</span><span class="n">settings</span>
</span><span class='line'>
</span><span class='line'><span class="p">[</span><span class="n">deploy</span><span class="p">:</span><span class="n">local</span><span class="o">-</span><span class="n">target</span><span class="p">]</span>
</span><span class='line'><span class="n">url</span> <span class="o">=</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">localhost</span><span class="p">:</span><span class="mi">6800</span><span class="o">/</span>
</span><span class='line'><span class="n">project</span> <span class="o">=</span> <span class="n">projectX</span>
</span><span class='line'>
</span><span class='line'><span class="p">[</span><span class="n">deploy</span><span class="p">:</span><span class="n">aws</span><span class="o">-</span><span class="n">target</span><span class="p">]</span>
</span><span class='line'><span class="n">url</span> <span class="o">=</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">my</span><span class="o">-</span><span class="n">ec2</span><span class="o">.</span><span class="n">amazonaws</span><span class="o">.</span><span class="n">com</span><span class="p">:</span><span class="mi">6800</span><span class="o">/</span>
</span><span class='line'><span class="n">project</span> <span class="o">=</span> <span class="n">projectX</span>
</span></code></pre></td></tr></table></div></figure>


<p>Here we have added two scrapyd deployment targets, one to localhost and one to the EC2 instance.</p>

<p>3) Verify the targets with the command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>scrapyd-deploy -l</span></code></pre></td></tr></table></div></figure>


<p>you should see</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>local-target           http://localhost:6800/
</span><span class='line'>aws-target             http://my-ec2.amazonaws.com:6800/</span></code></pre></td></tr></table></div></figure>


<h3>Deploy the crawler to EC2</h3>

<p>Make sure scrapyd is running on the target instance. For our EC2 instance we can check this by using one of the scrapy web service commands or in a browser navigate to the scrapyd web page (format: my-ec2.amazonaws.com:6800). Note: after I had scrapyd installed on EC2, if I stopped and restarted the instance, scrapyd would be run on startup. When I tried to run scrapyd I got an error “port 6800 in use”. If you get a similar error check if scrapyd is already running.</p>

<p>1) To deploy the spider to the EC2 target use the scrapyd command:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>scrapyd-deploy aws-target -p projectX</span></code></pre></td></tr></table></div></figure>


<p>you should see:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Packing version 1396800856    
</span><span class='line'>    Deploying to project "projectX" in http://my-ec2.amazonaws.com:6800/addversion.json
</span><span class='line'>    Server response (200):
</span><span class='line'>    {"status": "ok", "project": "projectX", "version": "1396800856", "spiders":1}</span></code></pre></td></tr></table></div></figure>


<p>2) Verify the deployment using the scrapyd web service:</p>

<figure class='code'><figcaption><span>scrapyd command  </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$> curl http://my-ec2.amazonaws.com:6800/listprojects.json</span></code></pre></td></tr></table></div></figure>


<p>you should see:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{"status": ok, "projects": ["projectX"]}</span></code></pre></td></tr></table></div></figure>


<p>or you can refresh the scrapyd webpage on your remote instance and Available projects</p>

<h3>Schedule and instance of the crawler</h3>

<p>1) Use the scrapyd web service to schedule to the spider. Note: for the spiders I needed to run, each had multiple constructor parameters. To schedule a spider with constructor parameters, each parameter must be preceded by -d and they must be in the order as they appear in the spider constructor. For this example, the constructor parameters are <em>session_id</em>, <em>seed_id</em>, and <em>seed_url</em>. The particular spider to be used is <em>spider2b</em>:</p>

<figure class='code'><figcaption><span>scrapyd command </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curl http://my-ec2.amazonaws.com:6800/schedule.json -d project=projectX -d spider=spider2b -d session_id=33 -d seed_id=54 -d seed_url=http://www.blah.com/</span></code></pre></td></tr></table></div></figure>


<p>you should see a response similar to:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{"status": "ok", "jobid": "c77c633ac28011e3ac0a0a32be087ede"}</span></code></pre></td></tr></table></div></figure>


<p>2) Verify the job:</p>

<figure class='code'><figcaption><span>scrapyd command </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curl http://my-ec2.amazonaws.com:6800/listjobs.json?project=projectX</span></code></pre></td></tr></table></div></figure>


<p>will show:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{"status": "ok", "running": [{"id": "c77c633ac28011e3ac0a0a32be087ede", "spider": "spider2b"}], "finished": [], "pending": []}</span></code></pre></td></tr></table></div></figure>


<p>or you can refresh the scrapyd webpage on your remote instance and check Jobs</p>

<p>3) To stop a job, use the following</p>

<figure class='code'><figcaption><span>scrapyd command </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curl http://my-ec2.amazonaws.com:6800/cancel.json -d project=simple -d job=c77c633ac28011e3ac0a0a32be087ede</span></code></pre></td></tr></table></div></figure>


<p>you should see:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{"status": "ok", "prevstate": "running"}</span></code></pre></td></tr></table></div></figure>


<p>Note that the <em>schedule</em> and <em>cancel</em> commands of the scrapyd webservice are not immediate, so give them a bit to take affect. When getting started, the scrapyd web page on the EC2 instance is the easiest way of viewing the logs and output items.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Scrapy to MongoDB]]></title>
    <link href="http://bgrva.github.io/blog/2014/03/23/scraping-to-mongodb/"/>
    <updated>2014-03-23T20:11:01-04:00</updated>
    <id>http://bgrva.github.io/blog/2014/03/23/scraping-to-mongodb</id>
    <content type="html"><![CDATA[<p>Now that we can crawl some sites (based on the previous posts), we need to persist the data somewhere where it can be retrieved and processed for analysis. Recall that the goal of the scraper was to harvest connections between domains in order to generate a model of a specific industry’s on-line presence. In Scrapy, <a href="http://doc.scrapy.org/en/latest/topics/item-pipeline.html">Item Pipelines</a> are the prescribed mechanism by which scraped items can be persisted to a data store. In this post, we will be using a custom pipeline extension for <a href="http://www.mongodb.org/">MongoDB</a> which we will further customize to check for duplicates. The code examples in this post build upon those in the previous examples. It is also assumed that you have some familiarity with MongoDB and have a working (basic) crawl spider. It does not cover installing Scrapy, MongoDB, or any dependencies, (there is plenty of good documentation on these subjects). Before continuing, you will need to install the following (in addition to having Scrapy working):</p>

<p>– <a href="http://www.mongodb.org/">MongoDB</a><br/>
– <a href="https://github.com/sebdah/scrapy-mongodb">Scrapy-MongoDB</a>, an item pipeline extension written by Sebastian Dahlgren<br/></p>

<p>Once installed, the first step will be to get Scrapy-MongoDB working and saving to a collection. Once you’ve got MongoDB installed, create a database named scrapy and within it, a collection named items. You can use the crawl spider from the previous posts and update the settings.py file to use Scrapy-MongoDB. A quick note about MongoDB ids: mongo will automatically add a unique id object with each item if and id field is not specified. We will use default id and benefit from it because the default MongoDB id object contains an embedded <a href="http://docs.mongodb.org/manual/reference/method/ObjectId.getTimestamp/#ObjectId.getTimestamp">date-time stamp</a>. Once you get Scrapy-MongoDB working and you are saving to a collection, we need to extend the <a href="https://github.com/sebdah/scrapy-mongodb/blob/master/scrapy_mongodb.py">MongoDBPipeline</a> class to include behavior to check for duplicates. A duplicate of the example item is one in which the following fields match:</p>

<p>– Session_id<br/>
– Current_url<br/>
– Referring_url<br/></p>

<p>The <em>session_id</em> is used to group items from different harvests. We want to persist a single connection between two given urls for each harvest session. The <em>current_url</em> and <em>referring_url</em> will be used to represent the connection between two domains and will be used to generate a directed graph for the model, (a connection between two valid business backed domains can be used to infer a relationship which in turn can be used in social network analysis, more on this later …).</p>

<p>The new class will be called <em>CustomMongoDBPipeline</em> and should be placed within the <em>pipelines.py</em> file in the scrapy project folder. You can keep the default pipeline initialized with the project in the same file and switch back by changing the settings file.</p>

<figure class='code'><figcaption><span>pipelines.py </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">scrapy.exceptions</span> <span class="kn">import</span> <span class="n">DropItem</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">scrapy_mongodb</span> <span class="kn">import</span> <span class="n">MongoDBPipeline</span>
</span><span class='line'>
</span><span class='line'><span class="k">class</span> <span class="nc">CustomMongoDBPipeline</span><span class="p">(</span><span class="n">MongoDBPipeline</span><span class="p">):</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">process_item</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
</span><span class='line'>        <span class="c"># the following lines are a duplication of MongoDBPipeline.process_item()</span>
</span><span class='line'>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s">&#39;buffer&#39;</span><span class="p">]:</span>
</span><span class='line'>            <span class="bp">self</span><span class="o">.</span><span class="n">current_item</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>            <span class="n">item</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s">&#39;append_timestamp&#39;</span><span class="p">]:</span>
</span><span class='line'>                <span class="n">item</span><span class="p">[</span><span class="s">&#39;scrapy-mongodb&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span> <span class="s">&#39;ts&#39;</span><span class="p">:</span> <span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">utcnow</span><span class="p">()</span> <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>            <span class="bp">self</span><span class="o">.</span><span class="n">item_buffer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_item</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s">&#39;buffer&#39;</span><span class="p">]:</span>
</span><span class='line'>                <span class="bp">self</span><span class="o">.</span><span class="n">current_item</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'>                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">insert_item</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">item_buffer</span><span class="p">,</span> <span class="n">spider</span><span class="p">)</span>
</span><span class='line'>            <span class="k">else</span><span class="p">:</span>
</span><span class='line'>                <span class="k">return</span> <span class="n">item</span>
</span><span class='line'>
</span><span class='line'>        <span class="c"># if the connection exists, don&#39;t save it</span>
</span><span class='line'>        <span class="n">matching_item</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">collection</span><span class="o">.</span><span class="n">find_one</span><span class="p">(</span>
</span><span class='line'>            <span class="p">{</span><span class="s">&#39;session_id&#39;</span><span class="p">:</span> <span class="n">item</span><span class="p">[</span><span class="s">&#39;session_id&#39;</span><span class="p">],</span>
</span><span class='line'>             <span class="s">&#39;referring_url&#39;</span><span class="p">:</span> <span class="n">item</span><span class="p">[</span><span class="s">&#39;referring_url&#39;</span><span class="p">],</span>
</span><span class='line'>             <span class="s">&#39;current_url&#39;</span><span class="p">:</span> <span class="n">item</span><span class="p">[</span><span class="s">&#39;current_url&#39;</span><span class="p">]}</span>
</span><span class='line'>        <span class="p">)</span>
</span><span class='line'>        <span class="k">if</span> <span class="n">matching_item</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
</span><span class='line'>            <span class="k">raise</span> <span class="n">DropItem</span><span class="p">(</span>
</span><span class='line'>                <span class="s">&quot;Duplicate found for </span><span class="si">%s</span><span class="s">, </span><span class="si">%s</span><span class="s">&quot;</span> <span class="o">%</span>
</span><span class='line'>                <span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="s">&#39;referring_url&#39;</span><span class="p">],</span> <span class="n">item</span><span class="p">[</span><span class="s">&#39;current_url&#39;</span><span class="p">])</span>
</span><span class='line'>            <span class="p">)</span>
</span><span class='line'>        <span class="k">else</span><span class="p">:</span>
</span><span class='line'>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">insert_item</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">spider</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Lines 9-22 are a duplication of the parent class MongoDBPipeline.process_item() method to maintain compatability with the Scrapy-MongoDB configuration options. Line 25 is where we retrieve an entry that matches the specified fields. If an entry is found, then the current item is dropped and we return to crawling. The settings are:</p>

<figure class='code'><figcaption><span>settings.py </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">BOT_NAME</span> <span class="o">=</span> <span class="s">&#39;farm2&#39;</span>
</span><span class='line'>
</span><span class='line'><span class="n">SPIDER_MODULES</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;farm2.spiders&#39;</span><span class="p">]</span>
</span><span class='line'><span class="n">NEWSPIDER_MODULE</span> <span class="o">=</span> <span class="s">&#39;farm2.spiders&#39;</span>
</span><span class='line'>
</span><span class='line'><span class="c">#set to 0 for no depth limit</span>
</span><span class='line'><span class="n">DEPTH_LIMIT</span> <span class="o">=</span> <span class="mi">3</span>
</span><span class='line'><span class="n">DOWNLOAD_DELAY</span> <span class="o">=</span> <span class="mi">2</span>
</span><span class='line'><span class="n">CONCURRENT_REQUESTS_PER_DOMAIN</span> <span class="o">=</span> <span class="mi">4</span>
</span><span class='line'>
</span><span class='line'><span class="n">ITEM_PIPELINES</span> <span class="o">=</span> <span class="p">{</span>
</span><span class='line'>    <span class="s">&#39;farm2.pipelines.CustomMongoDBPipeline&#39;</span><span class="p">:</span> <span class="mi">100</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="c"># &#39;scrapy_mongodb.MongoDBPipeline&#39; connection</span>
</span><span class='line'><span class="n">MONGODB_URI</span> <span class="o">=</span> <span class="s">&#39;mongodb://localhost:27017&#39;</span>
</span><span class='line'><span class="n">MONGODB_DATABASE</span> <span class="o">=</span> <span class="s">&#39;scrapy&#39;</span>
</span><span class='line'><span class="n">MONGODB_COLLECTION</span> <span class="o">=</span> <span class="s">&#39;items&#39;</span>
</span></code></pre></td></tr></table></div></figure>


<p>Recall you can set the session_id from the command line</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>scrapy crawl farm2 -a session_id=337</span></code></pre></td></tr></table></div></figure>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Scrapy After the Tutorials Part 2]]></title>
    <link href="http://bgrva.github.io/blog/2014/03/08/scrapy-after-tutorials-part-2/"/>
    <updated>2014-03-08T10:22:33-05:00</updated>
    <id>http://bgrva.github.io/blog/2014/03/08/scrapy-after-tutorials-part-2</id>
    <content type="html"><![CDATA[<p>As described in the previous post, the scraper will be crawling over extended periods of time. Filtering out links which do not need to be crawled is one way of improving performance: less links to crawl = less items to process. In this example, I hope to demonstrate how to filter the links to be crawled. So how does the scraper determine which links to follow and how can we modify this behavior? Using step #7 in the <a href="http://doc.scrapy.org/en/latest/topics/architecture.html#data-flow">Data Flow</a> as reference:</p>

<blockquote><p>The Spider processes the Response and returns scraped Items and new Requests (to follow) to the Engine.</p></blockquote>

<p>So when a response is sent to the spider for processing, the spider will first extract all links in the response and send them to the engine to be scheduled for crawling. The spider <a href="http://doc.scrapy.org/en/latest/topics/spiders.html?highlight=rule#crawling-rules">rules</a> control which links will be passed to the engine for crawling. Each rule uses a <a href="http://doc.scrapy.org/en/latest/topics/link-extractors.html">link extractor</a> with which you can specify the links to follow or drop using the available parameters. Many of the basic <a href="http://doc.scrapy.org/en/latest/topics/spiders.html?highlight=rule#crawlspider-example">examples</a> of crawl spiders demonstrate the ‘allow’ and ‘deny’ parameters for the rules. But for this example, we need a bit more functionality.</p>

<p>By default, for each response processed by the spider, the set of urls send to the engine for crawling will include every href tag in the response. To limit the amount of links that will be followed, we can remove the following types of links:</p>

<p>– any urls to the same domain as the response.url<br/>
– any relative urls<br/></p>

<p>To remove urls to the same domain, we will implement a filter_links() for the crawling Rule. To remove relative urls, we will add a regex to the link extractor to limit all urls returned to fully qualified urls, (e.g. start with <a href="http:">http:</a> or <a href="https:">https:</a>). The Item has not changed from the last post.</p>

<figure class='code'><figcaption><span>Spider </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">scrapy.contrib.spiders</span> <span class="kn">import</span> <span class="n">CrawlSpider</span><span class="p">,</span> <span class="n">Rule</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">scrapy.contrib.linkextractors.sgml</span> <span class="kn">import</span> <span class="n">SgmlLinkExtractor</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">scrapy.selector</span> <span class="kn">import</span> <span class="n">Selector</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">urlparse</span> <span class="kn">import</span> <span class="n">urlparse</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">farm1.items</span> <span class="kn">import</span> <span class="n">Farm1Item</span>
</span><span class='line'>
</span><span class='line'><span class="k">class</span> <span class="nc">Harvester2</span><span class="p">(</span><span class="n">CrawlSpider</span><span class="p">):</span>
</span><span class='line'>    <span class="n">name</span> <span class="o">=</span> <span class="s">&#39;Harvester2&#39;</span>
</span><span class='line'>    <span class="n">session_id</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
</span><span class='line'>    <span class="n">response_url</span> <span class="o">=</span> <span class="s">&quot;&quot;</span>
</span><span class='line'>    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">&quot;http://www.mmorpg.com&quot;</span><span class="p">]</span>
</span><span class='line'>    <span class="n">rules</span> <span class="o">=</span> <span class="p">(</span>
</span><span class='line'>        <span class="n">Rule</span> <span class="p">(</span>
</span><span class='line'>            <span class="n">SgmlLinkExtractor</span><span class="p">(</span>
</span><span class='line'>                <span class="n">allow</span><span class="o">=</span><span class="p">(</span><span class="s">&quot;((mailto\:|(news|(ht|f)tp(s?))\://){1}\S+)&quot;</span><span class="p">,</span> <span class="p">),),</span>
</span><span class='line'>            <span class="n">callback</span><span class="o">=</span><span class="s">&quot;parse_items&quot;</span><span class="p">,</span>
</span><span class='line'>            <span class="n">process_links</span><span class="o">=</span><span class="s">&quot;filter_links&quot;</span><span class="p">,</span>
</span><span class='line'>            <span class="n">follow</span><span class="o">=</span> <span class="bp">True</span><span class="p">),</span>
</span><span class='line'>    <span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">session_id</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span class='line'>        <span class="nb">super</span><span class="p">(</span><span class="n">Harvester2</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">session_id</span> <span class="o">=</span> <span class="n">session_id</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">parse_start_url</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">response_url</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">url</span>
</span><span class='line'>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">parse_items</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">parse_items</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">response_url</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">url</span>
</span><span class='line'>        <span class="n">sel</span> <span class="o">=</span> <span class="n">Selector</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</span><span class='line'>        <span class="n">items</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>        <span class="n">item</span> <span class="o">=</span> <span class="n">Farm1Item</span><span class="p">()</span>
</span><span class='line'>        <span class="n">item</span><span class="p">[</span><span class="s">&quot;session_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">session_id</span>
</span><span class='line'>        <span class="n">item</span><span class="p">[</span><span class="s">&quot;depth&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s">&quot;depth&quot;</span><span class="p">]</span>
</span><span class='line'>        <span class="n">item</span><span class="p">[</span><span class="s">&quot;title&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sel</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&#39;//title/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
</span><span class='line'>        <span class="n">item</span><span class="p">[</span><span class="s">&quot;current_url&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">url</span>
</span><span class='line'>        <span class="n">referring_url</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">headers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">&#39;Referer&#39;</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
</span><span class='line'>        <span class="n">item</span><span class="p">[</span><span class="s">&quot;referring_url&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">referring_url</span>
</span><span class='line'>        <span class="n">items</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
</span><span class='line'>        <span class="k">return</span> <span class="n">items</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">filter_links</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">links</span><span class="p">):</span>
</span><span class='line'>        <span class="n">baseDomain</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_base_domain</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">response_url</span><span class="p">)</span>
</span><span class='line'>        <span class="n">filteredLinks</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">link</span> <span class="ow">in</span> <span class="n">links</span><span class="p">:</span>
</span><span class='line'>            <span class="k">if</span> <span class="n">link</span><span class="o">.</span><span class="n">url</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="n">baseDomain</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span class='line'>                <span class="n">filteredLinks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">link</span><span class="p">)</span>
</span><span class='line'>        <span class="k">return</span> <span class="n">filteredLinks</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">get_base_domain</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">url</span><span class="p">):</span>
</span><span class='line'>        <span class="n">base</span> <span class="o">=</span> <span class="n">urlparse</span><span class="p">(</span><span class="n">url</span><span class="p">)</span><span class="o">.</span><span class="n">netloc</span>
</span><span class='line'>        <span class="k">if</span> <span class="n">base</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">&quot;WWW.&quot;</span><span class="p">):</span>
</span><span class='line'>            <span class="n">base</span> <span class="o">=</span> <span class="n">base</span><span class="p">[</span><span class="mi">4</span><span class="p">:]</span>
</span><span class='line'>        <span class="k">elif</span> <span class="n">base</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">&quot;FTP.&quot;</span><span class="p">):</span>
</span><span class='line'>            <span class="n">base</span> <span class="o">=</span> <span class="n">base</span><span class="p">[</span><span class="mi">4</span><span class="p">:]</span>
</span><span class='line'>        <span class="c"># drop any ports</span>
</span><span class='line'>        <span class="n">base</span> <span class="o">=</span> <span class="n">base</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&#39;:&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</span><span class='line'><span class="k">return</span> <span class="n">base</span>
</span></code></pre></td></tr></table></div></figure>


<p>Note: you can add this spider to the previous project by dropping it in the same folder as the other spider. As long as the file name and spider name are different, it will run with the same item and settings.</p>

<p>The response_url class variable (line 10) will maintain the current response.url and will be needed for filtering urls.</p>

<p>The <a href="http://doc.scrapy.org/en/latest/topics/spiders.html?highlight=rule#scrapy.contrib.spiders.CrawlSpider.parse_start_url">parse_start_url()</a> method (line 25) overrides the base definition and is called only for the defined start_urls and processes each start url as an item. Most importantly, it initializes the response_url variable before any crawling.</p>

<p>The parse_item() method has not changed from the last example.</p>

<p>The get_base_domain() method (line 51) returns the base domain for a url. For example, if ‘http ://www.b.com:334/x/y.htm?z’ is passed in, ‘b.com’ will be returned.</p>

<p>The filter_links() method will filter all links passed in and only return links to external domains. The base domain of the response_url is retrieved by get_base_domain() method (line 44). Any links in the input list of links which contain this base domain are filtered out. Only links to different (external) domains are returned. This method is assigned to the process_links parameter in the Rule (line line 40).</p>

<p>The allow parameter for the link extractor (line 15) is assigned the regular expression “((mailto:|(news|(ht|f)tp(s?))://){1}\S+)” which precludes any relative urls by only allowing urls that start with a <a href="http://en.wikipedia.org/wiki/URI_scheme">URI Scheme</a> (e.g. ftp, http, etc.).</p>

<p>When a response is sent to a spider for processing, the filter_links() method is called before the process_item() method. In this example, if the response_url variable is not set, it will fail. This is the reason we needed to use the parse_start_url() method, which is called for each defined start_url and allows us to set the response_url variable before any links are processed by filter_links(). This only allows fully qualified links to external urls to be sent to the engine for scheduled crawling.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Scrapy After the Tutorials Part 1]]></title>
    <link href="http://bgrva.github.io/blog/2014/03/04/scrapy-after-tutorials-part-1/"/>
    <updated>2014-03-04T09:22:33-05:00</updated>
    <id>http://bgrva.github.io/blog/2014/03/04/scrapy-after-tutorials-part-1</id>
    <content type="html"><![CDATA[<p>I was given the task of building a scalable web scraper to harvest connections between domains of a specific industry in order to generate a network model of that industry’s online presence. The scraper will need to run for a period of time, (say a week), and the resulting harvest would be the raw data from which the model would be generated. This harvesting process will need to be repeatable to create ‘snapshots’ of the network for future longitudinal analysis. The implementation will use <a href="http://www.scrapy.org/">scrapy</a> with a <a href="http://www.mongodb.org">MongoDB</a> back end on a linux platform to be run (ultimately) in AWS.</p>

<p>This post (and subsequent ones) will provide some code samples and documentation of issues faced during the process of getting the scraper operational. The intent is to help bridge the gap between the initial scrapy tutorials and real-world code. The examples assume you have scrapy installed and running, and have at least worked through the basic tutorials. I did find many of the <a href="https://github.com/scrapy/scrapy/wiki">tutorials</a> on the wiki very helpful and worked through several of them, (multiple times). Get a basic crawl spider up and running and then pick up here.</p>

<p>In this example, I hope to demonstrate the the following scrapy features:</p>

<p>   -Adding a spider parameter and using it from the command line<br/>
   -Getting current crawl depth and the referring url<br/>
   -Setting crawl depth limits<br/></p>

<p>The code samples below were from a scrapy project named <strong>farm1</strong></p>

<p>The item:</p>

<figure class='code'><figcaption><span>item  </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">scrapy.item</span> <span class="kn">import</span> <span class="n">Item</span><span class="p">,</span> <span class="n">Field</span>
</span><span class='line'>
</span><span class='line'><span class="k">class</span> <span class="nc">Farm1Item</span><span class="p">(</span><span class="n">Item</span><span class="p">):</span>
</span><span class='line'>    <span class="n">session_id</span> <span class="o">=</span> <span class="n">Field</span><span class="p">()</span>
</span><span class='line'>    <span class="n">depth</span> <span class="o">=</span> <span class="n">Field</span><span class="p">()</span>
</span><span class='line'>    <span class="n">current_url</span> <span class="o">=</span> <span class="n">Field</span><span class="p">()</span>
</span><span class='line'>    <span class="n">referring_url</span> <span class="o">=</span> <span class="n">Field</span><span class="p">()</span>
</span><span class='line'>    <span class="n">title</span> <span class="o">=</span> <span class="n">Field</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure>


<p><em>session_id</em>: a unique session id for each scrapy run or harvest<br/>
<em>depth</em>: the depth of the current page with respect to the start url<br/>
<em>current_url</em>: the url of the current page being processed<br/>
<em>referring_url</em>: the url of the site which was linked to the current page<br/></p>

<p>The crawl spider:</p>

<figure class='code'><figcaption><span>spider  </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">scrapy.contrib.spiders</span> <span class="kn">import</span> <span class="n">CrawlSpider</span><span class="p">,</span> <span class="n">Rule</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">scrapy.contrib.linkextractors.sgml</span> <span class="kn">import</span> <span class="n">SgmlLinkExtractor</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">scrapy.selector</span> <span class="kn">import</span> <span class="n">Selector</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">farm1.items</span> <span class="kn">import</span> <span class="n">Farm1Item</span>
</span><span class='line'>
</span><span class='line'><span class="k">class</span> <span class="nc">Harvester1</span><span class="p">(</span><span class="n">CrawlSpider</span><span class="p">):</span>
</span><span class='line'>    <span class="n">name</span> <span class="o">=</span> <span class="s">&#39;Harvester1&#39;</span>
</span><span class='line'>    <span class="n">session_id</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
</span><span class='line'>    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">&quot;http://www.example.com&quot;</span><span class="p">]</span>
</span><span class='line'>    <span class="n">rules</span> <span class="o">=</span> <span class="p">(</span> <span class="n">Rule</span> <span class="p">(</span><span class="n">SgmlLinkExtractor</span><span class="p">(</span><span class="n">allow</span><span class="o">=</span><span class="p">(</span><span class="s">&quot;&quot;</span><span class="p">,</span> <span class="p">),),</span>
</span><span class='line'>                <span class="n">callback</span><span class="o">=</span><span class="s">&quot;parse_items&quot;</span><span class="p">,</span>  <span class="n">follow</span><span class="o">=</span> <span class="bp">True</span><span class="p">),</span>
</span><span class='line'>    <span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">session_id</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span class='line'>        <span class="nb">super</span><span class="p">(</span><span class="n">Harvester1</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">session_id</span> <span class="o">=</span> <span class="n">session_id</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">parse_items</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
</span><span class='line'>        <span class="n">sel</span> <span class="o">=</span> <span class="n">Selector</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</span><span class='line'>        <span class="n">items</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>        <span class="n">item</span> <span class="o">=</span> <span class="n">Farm1Item</span><span class="p">()</span>
</span><span class='line'>        <span class="n">item</span><span class="p">[</span><span class="s">&quot;session_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">session_id</span>
</span><span class='line'>        <span class="n">item</span><span class="p">[</span><span class="s">&quot;depth&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s">&quot;depth&quot;</span><span class="p">]</span>
</span><span class='line'>        <span class="n">item</span><span class="p">[</span><span class="s">&quot;current_url&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">url</span>
</span><span class='line'>        <span class="n">referring_url</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">headers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">&#39;Referer&#39;</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
</span><span class='line'>        <span class="n">item</span><span class="p">[</span><span class="s">&quot;referring_url&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">referring_url</span>
</span><span class='line'>        <span class="n">item</span><span class="p">[</span><span class="s">&quot;title&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sel</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&#39;//title/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
</span><span class='line'>        <span class="n">items</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
</span><span class='line'>        <span class="k">return</span> <span class="n">items</span>
</span></code></pre></td></tr></table></div></figure>


<p>The spider uses the <a href="http://doc.scrapy.org/en/latest/topics/link-extractors.html#sgmllinkextractor">SgmlLinkExtractor</a> and follows every link, (a later post will cover filtering which links to follow).</p>

<h4>Adding a spider parameter and using it from the command line</h4>

<p>Lines 14-16 in the spider shows the constructor which has a session_id parameter with a defaul assignment. The session id is assigned to the spider and persisted with each item processed and will be used to identify items from different harvest sessions. Defining the parameter in the constructor allows using it from the command line:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>x:~$ scrapy crawl Harvester7 -a session_id=337</span></code></pre></td></tr></table></div></figure>


<h4>Getting current crawl depth and the referring url</h4>

<p>Line 23 is where the current depth of the crawl is retrieved. The ‘depth’ key word is one of several <a href="http://doc.scrapy.org/en/latest/topics/request-response.html?highlight=meta#request-meta-special-keys">predefined keys</a> in the meta dictionary for the request and response objects. The depth value will be used in the analysis phase.</p>

<p>Line 25 shows how to retrieve the referring url. The goal of this project was harvesting connections between domains, not just data from individual pages. For each item processed, the connection between two links: <em>referring_url –> current_url</em> is stored. Implied with each connection is the directionality of the link which will help build a directed graph for analysis. This is enabled by default in the <a href="https://scrapy.readthedocs.org/en/latest/topics/settings.html#std:setting-SPIDER_MIDDLEWARES_BASE">default middleware settings</a>, (and note that ‘Referer’ is the correct usage).</p>

<h4>Setting crawl depth limits</h4>

<p>Rather than use ctrl-c to kill the crawling spider, you can set a depth limit at which the spider will not go beyond. I found this helpful during testing. DEPTH_LIMIT is a predefined setting that can be assigned in your settings file. This was the only additional setting used in this example other than the defaults created with the project.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>DEPTH_LIMIT = 3</span></code></pre></td></tr></table></div></figure>


<p>The depth limit can also be set in the <a href="http://doc.scrapy.org/en/latest/topics/settings.html?highlight=depth#global-overrides">command line</a>, (as can all pre-defined settings):</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>x:~$ scrapy crawl Harvester1 –s DEPTH_LIMIT=2</span></code></pre></td></tr></table></div></figure>


<p>The command line assignment will take priority of the settings file. Note that the depth limit will have little affect if you are running a broad crawl. Ultimately, when this scraper is released into the wild, it will probably be set to run a <a href="http://doc.scrapy.org/en/latest/topics/broad-crawls.html?highlight=broad#broad-crawls">broad crawl</a>. But it will still need to troll deep to really pull out much of a domain’s public connections. As to how this will be handled, (a mix of broad + deep crawls), I am not sure but it will be documented here once it is figured out.</p>
]]></content>
  </entry>
  
</feed>
